{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654b4272",
   "metadata": {},
   "source": [
    "## Neural Networks classification with Pytorch\n",
    "\n",
    "For readers interested in a more detailed exploration of PyTorch, we recommend referring to the official PyTorch website and its extensive documentation and tutorials (https://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f1ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# We first need to import torch\n",
    "# If you dont have torch, visit https://pytorch.org/get-started/locally/ and go through the setup steps\n",
    "\n",
    "# Import torch and check version\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30495c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check if cuda is available on our device and enable it\n",
    "# Otherwise we will work on cpu\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
    "else:\n",
    "    device = \"cpu\" # Default to CPU if no GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d951a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c415b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset for the multiclass classification\n",
    "df = pd.read_csv('sheep_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5403f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split into features and labels\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7ca2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64626, 82), (64626,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc14f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#'y' is our categorical labels array\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(y)\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f88dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51700, 12926, 51700, 12926)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    encoded_labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42) \n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab170eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b28faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning training the data into tensors\n",
    "X_train = torch.from_numpy(X_train).type(torch.float)\n",
    "y_train = torch.from_numpy(y_train).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec3a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning test data into tensors\n",
    "X_test = torch.from_numpy(X_test).type(torch.float)\n",
    "y_test = torch.from_numpy(y_test).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c41482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([51700, 82]),\n",
       " torch.Size([51700]),\n",
       " torch.Size([12926, 82]),\n",
       " torch.Size([12926]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "279e381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MulticlassClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MulticlassClassifier, self).__init__()\n",
    "        # Define the layers of the neural network\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # First linear layer\n",
    "        self.fc2 = nn.Linear(64, 128)         # Second linear layer\n",
    "        self.fc3 = nn.Linear(128, 64)         # Third linear layer\n",
    "        self.fc4 = nn.Linear(64, num_classes) # Output layer\n",
    "\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        x = self.relu(self.fc1(x))  # Activation function after first layer\n",
    "        x = self.relu(self.fc2(x))  # Activation function after second layer\n",
    "        x = self.relu(self.fc3(x))  # Activation function after third layer\n",
    "        x = self.fc4(x)             # No activation function in the output layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "782d3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 82  \n",
    "num_classes = 5   \n",
    "\n",
    "multiclass_model = MulticlassClassifier(num_features, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86e596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# loss and optimizer function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(multiclass_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5328eee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Epoch: 0 | Training Loss: 1.55996, Training Accuracy: 52.95% | Test Loss: 1.54117, Test Accuracy: 56.60%\n",
      "At Epoch: 10 | Training Loss: 1.29415, Training Accuracy: 63.51% | Test Loss: 1.25302, Test Accuracy: 63.65%\n",
      "At Epoch: 20 | Training Loss: 0.82347, Training Accuracy: 65.54% | Test Loss: 0.78344, Test Accuracy: 66.17%\n",
      "At Epoch: 30 | Training Loss: 0.56536, Training Accuracy: 76.82% | Test Loss: 0.55207, Test Accuracy: 77.46%\n",
      "At Epoch: 40 | Training Loss: 0.46899, Training Accuracy: 79.15% | Test Loss: 0.46420, Test Accuracy: 79.56%\n",
      "At Epoch: 50 | Training Loss: 0.41104, Training Accuracy: 81.37% | Test Loss: 0.40861, Test Accuracy: 81.67%\n",
      "At Epoch: 60 | Training Loss: 0.36694, Training Accuracy: 83.42% | Test Loss: 0.36500, Test Accuracy: 83.56%\n",
      "At Epoch: 70 | Training Loss: 0.33154, Training Accuracy: 85.44% | Test Loss: 0.33061, Test Accuracy: 85.16%\n",
      "At Epoch: 80 | Training Loss: 0.30091, Training Accuracy: 87.16% | Test Loss: 0.29981, Test Accuracy: 86.85%\n",
      "At Epoch: 90 | Training Loss: 0.27366, Training Accuracy: 88.55% | Test Loss: 0.27256, Test Accuracy: 88.28%\n",
      "At Epoch: 100 | Training Loss: 0.24820, Training Accuracy: 89.79% | Test Loss: 0.24780, Test Accuracy: 89.79%\n",
      "At Epoch: 110 | Training Loss: 0.22446, Training Accuracy: 90.95% | Test Loss: 0.22617, Test Accuracy: 90.71%\n",
      "At Epoch: 120 | Training Loss: 0.20294, Training Accuracy: 91.92% | Test Loss: 0.20750, Test Accuracy: 91.56%\n",
      "At Epoch: 130 | Training Loss: 0.18414, Training Accuracy: 92.77% | Test Loss: 0.19135, Test Accuracy: 92.42%\n",
      "At Epoch: 140 | Training Loss: 0.16800, Training Accuracy: 93.55% | Test Loss: 0.17761, Test Accuracy: 93.06%\n",
      "At Epoch: 150 | Training Loss: 0.15559, Training Accuracy: 94.07% | Test Loss: 0.16699, Test Accuracy: 93.58%\n",
      "At Epoch: 160 | Training Loss: 0.14425, Training Accuracy: 94.56% | Test Loss: 0.15761, Test Accuracy: 93.93%\n",
      "At Epoch: 170 | Training Loss: 0.13549, Training Accuracy: 94.90% | Test Loss: 0.14998, Test Accuracy: 94.19%\n",
      "At Epoch: 180 | Training Loss: 0.12765, Training Accuracy: 95.18% | Test Loss: 0.14293, Test Accuracy: 94.64%\n",
      "At Epoch: 190 | Training Loss: 0.12082, Training Accuracy: 95.49% | Test Loss: 0.13723, Test Accuracy: 94.74%\n",
      "At Epoch: 200 | Training Loss: 0.11467, Training Accuracy: 95.68% | Test Loss: 0.13190, Test Accuracy: 95.00%\n",
      "At Epoch: 210 | Training Loss: 0.10893, Training Accuracy: 95.90% | Test Loss: 0.12712, Test Accuracy: 95.13%\n",
      "At Epoch: 220 | Training Loss: 0.10523, Training Accuracy: 95.97% | Test Loss: 0.12237, Test Accuracy: 95.37%\n",
      "At Epoch: 230 | Training Loss: 0.09960, Training Accuracy: 96.26% | Test Loss: 0.12033, Test Accuracy: 95.33%\n",
      "At Epoch: 240 | Training Loss: 0.09558, Training Accuracy: 96.42% | Test Loss: 0.11623, Test Accuracy: 95.50%\n",
      "At Epoch: 250 | Training Loss: 0.09150, Training Accuracy: 96.58% | Test Loss: 0.11302, Test Accuracy: 95.64%\n",
      "At Epoch: 260 | Training Loss: 0.08773, Training Accuracy: 96.75% | Test Loss: 0.11026, Test Accuracy: 95.75%\n",
      "At Epoch: 270 | Training Loss: 0.08411, Training Accuracy: 96.90% | Test Loss: 0.10729, Test Accuracy: 95.81%\n",
      "At Epoch: 280 | Training Loss: 0.08175, Training Accuracy: 96.90% | Test Loss: 0.10563, Test Accuracy: 96.00%\n",
      "At Epoch: 290 | Training Loss: 0.07912, Training Accuracy: 96.97% | Test Loss: 0.10367, Test Accuracy: 96.08%\n",
      "At Epoch: 300 | Training Loss: 0.07566, Training Accuracy: 97.23% | Test Loss: 0.10284, Test Accuracy: 95.96%\n",
      "At Epoch: 310 | Training Loss: 0.07295, Training Accuracy: 97.30% | Test Loss: 0.09940, Test Accuracy: 96.22%\n",
      "At Epoch: 320 | Training Loss: 0.07064, Training Accuracy: 97.40% | Test Loss: 0.09840, Test Accuracy: 96.18%\n",
      "At Epoch: 330 | Training Loss: 0.06832, Training Accuracy: 97.49% | Test Loss: 0.09720, Test Accuracy: 96.29%\n",
      "At Epoch: 340 | Training Loss: 0.06610, Training Accuracy: 97.60% | Test Loss: 0.09560, Test Accuracy: 96.39%\n",
      "At Epoch: 350 | Training Loss: 0.06392, Training Accuracy: 97.70% | Test Loss: 0.09405, Test Accuracy: 96.52%\n",
      "At Epoch: 360 | Training Loss: 0.06179, Training Accuracy: 97.80% | Test Loss: 0.09300, Test Accuracy: 96.59%\n",
      "At Epoch: 370 | Training Loss: 0.06053, Training Accuracy: 97.81% | Test Loss: 0.09432, Test Accuracy: 96.40%\n",
      "At Epoch: 380 | Training Loss: 0.05967, Training Accuracy: 97.84% | Test Loss: 0.09042, Test Accuracy: 96.70%\n",
      "At Epoch: 390 | Training Loss: 0.05663, Training Accuracy: 98.01% | Test Loss: 0.08961, Test Accuracy: 96.73%\n",
      "At Epoch: 400 | Training Loss: 0.05466, Training Accuracy: 98.08% | Test Loss: 0.08900, Test Accuracy: 96.73%\n",
      "At Epoch: 410 | Training Loss: 0.05309, Training Accuracy: 98.15% | Test Loss: 0.08830, Test Accuracy: 96.89%\n",
      "At Epoch: 420 | Training Loss: 0.05148, Training Accuracy: 98.22% | Test Loss: 0.08765, Test Accuracy: 96.91%\n",
      "At Epoch: 430 | Training Loss: 0.04999, Training Accuracy: 98.27% | Test Loss: 0.08750, Test Accuracy: 96.87%\n",
      "At Epoch: 440 | Training Loss: 0.04856, Training Accuracy: 98.33% | Test Loss: 0.08697, Test Accuracy: 96.92%\n",
      "At Epoch: 450 | Training Loss: 0.05048, Training Accuracy: 98.18% | Test Loss: 0.09212, Test Accuracy: 96.58%\n",
      "At Epoch: 460 | Training Loss: 0.04594, Training Accuracy: 98.40% | Test Loss: 0.08696, Test Accuracy: 96.88%\n",
      "At Epoch: 470 | Training Loss: 0.04480, Training Accuracy: 98.47% | Test Loss: 0.08603, Test Accuracy: 96.97%\n",
      "At Epoch: 480 | Training Loss: 0.04375, Training Accuracy: 98.51% | Test Loss: 0.08521, Test Accuracy: 97.00%\n",
      "At Epoch: 490 | Training Loss: 0.04271, Training Accuracy: 98.55% | Test Loss: 0.08463, Test Accuracy: 97.01%\n",
      "At Epoch: 500 | Training Loss: 0.04160, Training Accuracy: 98.60% | Test Loss: 0.08458, Test Accuracy: 97.03%\n",
      "At Epoch: 510 | Training Loss: 0.04051, Training Accuracy: 98.65% | Test Loss: 0.08396, Test Accuracy: 97.06%\n",
      "At Epoch: 520 | Training Loss: 0.04045, Training Accuracy: 98.65% | Test Loss: 0.08437, Test Accuracy: 96.99%\n",
      "At Epoch: 530 | Training Loss: 0.04081, Training Accuracy: 98.61% | Test Loss: 0.08706, Test Accuracy: 96.92%\n",
      "At Epoch: 540 | Training Loss: 0.03841, Training Accuracy: 98.70% | Test Loss: 0.08488, Test Accuracy: 97.04%\n",
      "At Epoch: 550 | Training Loss: 0.03700, Training Accuracy: 98.80% | Test Loss: 0.08383, Test Accuracy: 97.12%\n",
      "At Epoch: 560 | Training Loss: 0.03602, Training Accuracy: 98.83% | Test Loss: 0.08300, Test Accuracy: 97.15%\n",
      "At Epoch: 570 | Training Loss: 0.03523, Training Accuracy: 98.86% | Test Loss: 0.08275, Test Accuracy: 97.12%\n",
      "At Epoch: 580 | Training Loss: 0.03440, Training Accuracy: 98.89% | Test Loss: 0.08306, Test Accuracy: 97.15%\n",
      "At Epoch: 590 | Training Loss: 0.03375, Training Accuracy: 98.92% | Test Loss: 0.08342, Test Accuracy: 97.15%\n",
      "At Epoch: 600 | Training Loss: 0.03517, Training Accuracy: 98.82% | Test Loss: 0.08703, Test Accuracy: 96.98%\n",
      "At Epoch: 610 | Training Loss: 0.03325, Training Accuracy: 98.91% | Test Loss: 0.08296, Test Accuracy: 97.21%\n",
      "At Epoch: 620 | Training Loss: 0.03165, Training Accuracy: 98.97% | Test Loss: 0.08306, Test Accuracy: 97.17%\n",
      "At Epoch: 630 | Training Loss: 0.03088, Training Accuracy: 99.00% | Test Loss: 0.08295, Test Accuracy: 97.16%\n",
      "At Epoch: 640 | Training Loss: 0.03048, Training Accuracy: 99.02% | Test Loss: 0.08426, Test Accuracy: 97.17%\n",
      "At Epoch: 650 | Training Loss: 0.03010, Training Accuracy: 99.04% | Test Loss: 0.08487, Test Accuracy: 97.16%\n",
      "At Epoch: 660 | Training Loss: 0.02910, Training Accuracy: 99.07% | Test Loss: 0.08419, Test Accuracy: 97.21%\n",
      "At Epoch: 670 | Training Loss: 0.02871, Training Accuracy: 99.10% | Test Loss: 0.08532, Test Accuracy: 97.18%\n",
      "At Epoch: 680 | Training Loss: 0.02844, Training Accuracy: 99.09% | Test Loss: 0.08388, Test Accuracy: 97.22%\n",
      "At Epoch: 690 | Training Loss: 0.02748, Training Accuracy: 99.15% | Test Loss: 0.08410, Test Accuracy: 97.26%\n",
      "At Epoch: 700 | Training Loss: 0.02669, Training Accuracy: 99.19% | Test Loss: 0.08422, Test Accuracy: 97.27%\n",
      "At Epoch: 710 | Training Loss: 0.02616, Training Accuracy: 99.21% | Test Loss: 0.08464, Test Accuracy: 97.26%\n",
      "At Epoch: 720 | Training Loss: 0.02556, Training Accuracy: 99.22% | Test Loss: 0.08504, Test Accuracy: 97.25%\n",
      "At Epoch: 730 | Training Loss: 0.02499, Training Accuracy: 99.23% | Test Loss: 0.08492, Test Accuracy: 97.32%\n",
      "At Epoch: 740 | Training Loss: 0.02448, Training Accuracy: 99.27% | Test Loss: 0.08535, Test Accuracy: 97.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Epoch: 750 | Training Loss: 0.02396, Training Accuracy: 99.30% | Test Loss: 0.08538, Test Accuracy: 97.29%\n",
      "At Epoch: 760 | Training Loss: 0.02360, Training Accuracy: 99.30% | Test Loss: 0.08617, Test Accuracy: 97.28%\n",
      "At Epoch: 770 | Training Loss: 0.02933, Training Accuracy: 98.95% | Test Loss: 0.09279, Test Accuracy: 97.07%\n",
      "At Epoch: 780 | Training Loss: 0.02387, Training Accuracy: 99.27% | Test Loss: 0.08890, Test Accuracy: 97.25%\n",
      "At Epoch: 790 | Training Loss: 0.02263, Training Accuracy: 99.32% | Test Loss: 0.08744, Test Accuracy: 97.31%\n",
      "At Epoch: 800 | Training Loss: 0.02181, Training Accuracy: 99.36% | Test Loss: 0.08683, Test Accuracy: 97.26%\n",
      "At Epoch: 810 | Training Loss: 0.02130, Training Accuracy: 99.38% | Test Loss: 0.08647, Test Accuracy: 97.29%\n",
      "At Epoch: 820 | Training Loss: 0.02091, Training Accuracy: 99.41% | Test Loss: 0.08652, Test Accuracy: 97.32%\n",
      "At Epoch: 830 | Training Loss: 0.02049, Training Accuracy: 99.40% | Test Loss: 0.08721, Test Accuracy: 97.31%\n",
      "At Epoch: 840 | Training Loss: 0.02005, Training Accuracy: 99.44% | Test Loss: 0.08725, Test Accuracy: 97.32%\n",
      "At Epoch: 850 | Training Loss: 0.01974, Training Accuracy: 99.44% | Test Loss: 0.08749, Test Accuracy: 97.36%\n",
      "At Epoch: 860 | Training Loss: 0.01986, Training Accuracy: 99.42% | Test Loss: 0.08800, Test Accuracy: 97.42%\n",
      "At Epoch: 870 | Training Loss: 0.01945, Training Accuracy: 99.44% | Test Loss: 0.08804, Test Accuracy: 97.40%\n",
      "At Epoch: 880 | Training Loss: 0.01913, Training Accuracy: 99.44% | Test Loss: 0.09001, Test Accuracy: 97.33%\n",
      "At Epoch: 890 | Training Loss: 0.01813, Training Accuracy: 99.51% | Test Loss: 0.08874, Test Accuracy: 97.38%\n",
      "At Epoch: 900 | Training Loss: 0.01856, Training Accuracy: 99.47% | Test Loss: 0.08932, Test Accuracy: 97.41%\n",
      "At Epoch: 910 | Training Loss: 0.01805, Training Accuracy: 99.48% | Test Loss: 0.08895, Test Accuracy: 97.45%\n",
      "At Epoch: 920 | Training Loss: 0.01712, Training Accuracy: 99.54% | Test Loss: 0.08925, Test Accuracy: 97.47%\n",
      "At Epoch: 930 | Training Loss: 0.01687, Training Accuracy: 99.56% | Test Loss: 0.09033, Test Accuracy: 97.41%\n",
      "At Epoch: 940 | Training Loss: 0.01646, Training Accuracy: 99.57% | Test Loss: 0.08999, Test Accuracy: 97.45%\n",
      "At Epoch: 950 | Training Loss: 0.01647, Training Accuracy: 99.58% | Test Loss: 0.09024, Test Accuracy: 97.43%\n",
      "At Epoch: 960 | Training Loss: 0.01649, Training Accuracy: 99.55% | Test Loss: 0.09084, Test Accuracy: 97.43%\n",
      "At Epoch: 970 | Training Loss: 0.01552, Training Accuracy: 99.61% | Test Loss: 0.09127, Test Accuracy: 97.48%\n",
      "At Epoch: 980 | Training Loss: 0.01600, Training Accuracy: 99.55% | Test Loss: 0.09390, Test Accuracy: 97.42%\n",
      "At Epoch: 990 | Training Loss: 0.01904, Training Accuracy: 99.37% | Test Loss: 0.09262, Test Accuracy: 97.45%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming multiclass_model, criterion (CrossEntropyLoss), optimizer are defined\n",
    "# Also assuming X_train, y_train, X_test, y_test are your datasets\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 1000\n",
    "\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train the model\n",
    "    multiclass_model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_log = multiclass_model(X_train)\n",
    "    # Convert logits to prediction labels for accuracy calculation\n",
    "    y_pred = torch.argmax(y_log, dim=1)\n",
    "\n",
    "    # loss and Accuracy\n",
    "    loss = criterion(y_log, y_train) \n",
    "    correct_train = (y_pred == y_train).sum().item()\n",
    "    train_accuracy = 100 * correct_train / len(y_train)\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Perform backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    #Testing the model using .eval()\n",
    "    multiclass_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass on test data\n",
    "        test_log = multiclass_model(X_test)\n",
    "        test_pred = torch.argmax(test_log, dim=1)\n",
    "\n",
    "        # Test loss and test accuracy\n",
    "        test_loss = criterion(test_log, y_test)\n",
    "        correct_test = (test_pred == y_test).sum().item()\n",
    "        test_accuracy = 100 * correct_test / len(y_test)\n",
    "\n",
    "    # Print training status\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"At Epoch: {epoch} | Training Loss: {loss:.5f}, Training Accuracy: {train_accuracy:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aec238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test dataset: 97.44700603434937%\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "multiclass_model.eval()\n",
    "\n",
    "# No gradient computation in evaluation to save memory and computations\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs = multiclass_model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = y_test.size(0)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test dataset: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb869e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     grazing       1.00      1.00      1.00      3186\n",
      "     resting       0.97      0.97      0.97      5568\n",
      "  scratching       0.92      0.90      0.91       116\n",
      "    standing       0.95      0.94      0.95      2800\n",
      "     walking       0.99      1.00      0.99      1256\n",
      "\n",
      "    accuracy                           0.97     12926\n",
      "   macro avg       0.97      0.96      0.96     12926\n",
      "weighted avg       0.97      0.97      0.97     12926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Retrieve class names from label encoder\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Set model to evaluation mode\n",
    "multiclass_model.eval()\n",
    "\n",
    "# No gradient computation in evaluation to save memory and computations\n",
    "with torch.no_grad():\n",
    "    outputs = multiclass_model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Convert the tensors back to numpy arrays for sklearn compatibility\n",
    "y_test_np = y_test.cpu().numpy()\n",
    "predicted_np = predicted.cpu().numpy()\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test_np, predicted_np, target_names=class_names)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd5488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
