{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d08064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64626, 83)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. Importing the libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv('sheep_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc5bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalise the features\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-1]  # All columns except the last are features\n",
    "y = df.iloc[:, -1]   # The last column is the label\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82fa3555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['grazing', 'resting', 'scratching', 'standing', 'walking'],\n",
       "       dtype=object),\n",
       " array([0, 0, 0, ..., 4, 4, 4]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Encode the categorical labels\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "label_names = encoder.classes_\n",
    "label_names, y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94af61c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64626, 1, 82)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Reshape data for CNN input (Batch, Channels, Length)\n",
    "X_reshaped = X_normalized.reshape(-1,1,82)\n",
    "X_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b737bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_reshaped, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18687e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64626, 1, 82]), torch.Size([64626]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape, y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fff91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create Dataset and DataLoader\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split the dataset into training and temporary dataset\n",
    "train_dataset, temp_dataset = train_test_split(dataset, test_size=0.3, \n",
    "                                               random_state=42)\n",
    "\n",
    "# Split the temporary dataset into validation and test datasets\n",
    "val_dataset, test_dataset = train_test_split(temp_dataset, test_size=0.5, \n",
    "                                             random_state=42)\n",
    "\n",
    "# Create DataLoaders for training, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6254d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define the CNN model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class AccelerometerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AccelerometerCNN, self).__init__()\n",
    "        # Assuming input shape [batch_size, 1, 82]\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1) # Output: [batch_size, 32, 82]\n",
    "        self.pool = nn.MaxPool1d(2) # Output: [batch_size, 32, 41]\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1) # Output: [batch_size, 64, 41]\n",
    "        # Apply pooling again: [batch_size, 64, 20]\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(64 * 20, 128) # Fully connected layers\n",
    "        self.fc2 = nn.Linear(128, 5) # Output layer, 5 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 20) # Flatten for fully connected layer\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8f455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Setup Early Stopping\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf7fa8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nklea\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nklea\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Initialize the Model, Loss Function, Optimizer, and Move to GPU\n",
    "\n",
    "# Initialize model\n",
    "model = AccelerometerCNN()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function with L2 Regularization (Weight Decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5) # L2 regularization\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience=20, min_delta=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70cf699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3322, Train Accuracy: 85.71%, Val Loss: 0.1897, Val Accuracy: 92.01%\n",
      "Epoch 2, Train Loss: 0.1939, Train Accuracy: 92.02%, Val Loss: 0.1500, Val Accuracy: 93.51%\n",
      "Epoch 3, Train Loss: 0.1601, Train Accuracy: 93.43%, Val Loss: 0.1311, Val Accuracy: 94.66%\n",
      "Epoch 4, Train Loss: 0.1400, Train Accuracy: 94.38%, Val Loss: 0.1143, Val Accuracy: 95.29%\n",
      "Epoch 5, Train Loss: 0.1229, Train Accuracy: 95.06%, Val Loss: 0.1133, Val Accuracy: 95.37%\n",
      "Epoch 6, Train Loss: 0.1105, Train Accuracy: 95.46%, Val Loss: 0.0971, Val Accuracy: 96.06%\n",
      "Epoch 7, Train Loss: 0.1026, Train Accuracy: 95.87%, Val Loss: 0.0913, Val Accuracy: 96.28%\n",
      "Epoch 8, Train Loss: 0.0934, Train Accuracy: 96.24%, Val Loss: 0.0908, Val Accuracy: 96.20%\n",
      "Epoch 9, Train Loss: 0.0864, Train Accuracy: 96.57%, Val Loss: 0.0916, Val Accuracy: 96.36%\n",
      "Epoch 10, Train Loss: 0.0817, Train Accuracy: 96.72%, Val Loss: 0.0822, Val Accuracy: 96.63%\n",
      "Epoch 11, Train Loss: 0.0750, Train Accuracy: 96.99%, Val Loss: 0.0808, Val Accuracy: 96.74%\n",
      "Epoch 12, Train Loss: 0.0721, Train Accuracy: 97.13%, Val Loss: 0.0747, Val Accuracy: 96.89%\n",
      "Epoch 13, Train Loss: 0.0668, Train Accuracy: 97.33%, Val Loss: 0.0741, Val Accuracy: 97.11%\n",
      "Epoch 14, Train Loss: 0.0644, Train Accuracy: 97.39%, Val Loss: 0.0737, Val Accuracy: 97.18%\n",
      "Epoch 15, Train Loss: 0.0623, Train Accuracy: 97.51%, Val Loss: 0.0743, Val Accuracy: 96.91%\n",
      "Epoch 16, Train Loss: 0.0593, Train Accuracy: 97.56%, Val Loss: 0.0735, Val Accuracy: 97.08%\n",
      "Epoch 17, Train Loss: 0.0580, Train Accuracy: 97.75%, Val Loss: 0.0699, Val Accuracy: 97.32%\n",
      "Epoch 18, Train Loss: 0.0529, Train Accuracy: 97.86%, Val Loss: 0.0732, Val Accuracy: 97.38%\n",
      "Epoch 19, Train Loss: 0.0519, Train Accuracy: 97.86%, Val Loss: 0.0690, Val Accuracy: 97.29%\n",
      "Epoch 20, Train Loss: 0.0510, Train Accuracy: 97.93%, Val Loss: 0.0653, Val Accuracy: 97.43%\n",
      "Epoch 21, Train Loss: 0.0507, Train Accuracy: 98.01%, Val Loss: 0.0658, Val Accuracy: 97.54%\n",
      "Epoch 22, Train Loss: 0.0470, Train Accuracy: 98.07%, Val Loss: 0.0721, Val Accuracy: 97.47%\n",
      "Epoch 23, Train Loss: 0.0465, Train Accuracy: 98.17%, Val Loss: 0.0641, Val Accuracy: 97.72%\n",
      "Epoch 24, Train Loss: 0.0454, Train Accuracy: 98.19%, Val Loss: 0.0708, Val Accuracy: 97.59%\n",
      "Epoch 25, Train Loss: 0.0432, Train Accuracy: 98.27%, Val Loss: 0.0694, Val Accuracy: 97.72%\n",
      "Epoch 26, Train Loss: 0.0421, Train Accuracy: 98.27%, Val Loss: 0.0677, Val Accuracy: 97.77%\n",
      "Epoch 27, Train Loss: 0.0414, Train Accuracy: 98.37%, Val Loss: 0.0676, Val Accuracy: 97.83%\n",
      "Epoch 28, Train Loss: 0.0396, Train Accuracy: 98.45%, Val Loss: 0.0681, Val Accuracy: 97.65%\n",
      "Epoch 29, Train Loss: 0.0403, Train Accuracy: 98.42%, Val Loss: 0.0714, Val Accuracy: 97.41%\n",
      "Epoch 30, Train Loss: 0.0391, Train Accuracy: 98.43%, Val Loss: 0.0668, Val Accuracy: 97.74%\n",
      "Epoch 31, Train Loss: 0.0354, Train Accuracy: 98.57%, Val Loss: 0.0639, Val Accuracy: 98.04%\n",
      "Epoch 32, Train Loss: 0.0367, Train Accuracy: 98.57%, Val Loss: 0.0668, Val Accuracy: 97.66%\n",
      "Epoch 33, Train Loss: 0.0368, Train Accuracy: 98.49%, Val Loss: 0.0673, Val Accuracy: 97.60%\n",
      "Epoch 34, Train Loss: 0.0340, Train Accuracy: 98.68%, Val Loss: 0.0623, Val Accuracy: 97.79%\n",
      "Epoch 35, Train Loss: 0.0363, Train Accuracy: 98.58%, Val Loss: 0.0698, Val Accuracy: 97.57%\n",
      "Epoch 36, Train Loss: 0.0360, Train Accuracy: 98.60%, Val Loss: 0.0650, Val Accuracy: 97.74%\n",
      "Epoch 37, Train Loss: 0.0342, Train Accuracy: 98.59%, Val Loss: 0.0616, Val Accuracy: 97.90%\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# 10. Model training and evaluation on validation set\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "max_epochs = 1000\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "168c9030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     grazing       0.99      1.00      1.00      2416\n",
      "     resting       0.98      0.97      0.98      4166\n",
      "  scratching       0.96      0.89      0.92        88\n",
      "    standing       0.95      0.96      0.96      2058\n",
      "     walking       1.00      1.00      1.00       966\n",
      "\n",
      "    accuracy                           0.98      9694\n",
      "   macro avg       0.98      0.96      0.97      9694\n",
      "weighted avg       0.98      0.98      0.98      9694\n",
      "\n",
      "Accuracy: 0.9789560552919332\n"
     ]
    }
   ],
   "source": [
    "# 11. Evaluate the model\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        y_true.extend(target.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Classification report with names of the labels\n",
    "target_names = encoder.classes_\n",
    "classification_report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "print(\"Classification Report:\\n\", classification_report)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3021e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
